# ğŸ§¹ SQL Data Cleaning and ğŸ“Š EDA on Layoffs Dataset

This project demonstrates a comprehensive approach to data cleaning using SQL and subsequent exploratory data analysis (EDA) on a dataset detailing layoffs in 2022. The original dataset is sourced from [Kaggle](https://www.kaggle.com/datasets/swaptr/layoffs-2022).

## ğŸ¯ Project Goals

The primary goals of this project are:

1. **ğŸš« Remove duplicates**: Ensure the dataset contains only unique entries.
2. **ğŸ”„ Standardize data**: Normalize values in various columns for consistency.
3. **ğŸ§½ Handle null and blank values**: Clean or impute missing and blank entries.
4. **ğŸ› ï¸ Optimize data structure**: Remove unnecessary columns and rows based on the analysis needs.

## ğŸ“ Dataset and File Structure

`layoffs.csv`: The dataset file.

The initial dataset includes several columns such as company, location, industry, total_laid_off, percentage_laid_off, date, stage, country, and funds_raised_millions. This data spans various industries and geographical locations.

`Data_cleaning_layoffs_proj.sql`: The Data cleaning process in SQL.

`EDA_layoffs.sql`: Exploratory Data Analysis conducted in SQL.



## ğŸ§¼ Data Cleaning Steps

1. **ğŸ” Duplicate Removal**: Identified and removed duplicate entries based on specific columns.
2. **ğŸ“ Data Standardization**:
   - Standardized company names and industry descriptions to a uniform format.
   - Corrected country names and standardized date formats.
3. **ğŸ§¹ Handling Nulls and Blanks**:
   - Converted blank entries to `NULL` for easier manipulation.
   - Filled missing industry data based on other entries from the same company.

## ğŸ” Exploratory Data Analysis (EDA)

Post-cleaning, various analyses were performed to understand:
- ğŸ“‰ Trends in layoffs by industry and location.
- ğŸ”— Correlation between layoffs and company funding.
- ğŸ“… Monthly and yearly patterns in layoffs.

## ğŸ› ï¸ Tools and Technologies

- **ğŸ—„ï¸ SQL**: Used for data manipulation and cleaning.
